---
title: "DM Project"
output: html_notebook
---

# Student's Adaptability Level in Online Education

------------------------------------------------------------------------

## The Goal of Collecting this Dataset:

The goal of our project is to build a model that can predict the adaptivity level of a student with a high degree of accuracy. We will be using classification and clustering to achieve this goal.

## Dataset Source:

The dataset was obtained from Kaggle.\
<https://www.kaggle.com/datasets/mdmahmudulhasansuzan/students-adaptability-level-in-online-education>

## General information:

Our dataset has 14 attributes and 1,205 objects.\
The class label is "Adaptivity Level".

## Our attributes are as follows:

|   Attribute Name    | Attribute Type |                    Description                    |            Possible Values            |
|:---------------:|:---------------:|:------------------:|:---------------:|
|       Gender        |     Binary     |               Student's gender type               |               Girl, Boy               |
|         Age         |    Ordinal     |                Student's age range                | 1-5, 6-10, 11-15, 16-20, 21-25, 26-30 |
|  Educational Level  |    Nominal     |       Student's education institution level       |      School, College, University      |
|  Institution Type   |     Binary     |       Student's education institution type        |      Government, Non-government       |
|     IT Student      |     Binary     |     Whether the student is studying IT or not     |                Yes, No                |
|      Location       |     Binary     | Whether the student is studying in their hometown |                Yes, No                |
|    Load-shedding    |     Binary     |              Level of load-shedding               |               High, Low               |
| Financial Condition |    Ordinal     |      Student's family's financial condition       |            Rich, Mid, Poor            |
|    Internet Type    |     Binary     |         Student's most used internet type         |           Wifi, Mobile Data           |
|    Network Type     |    Ordinal     |             Network connectivity type             |              2G, 3G, 4G               |
|   Class Duration    |    Ordinal     |      Student's daily class duration in hours      |              0, 1-3, 3-6              |
|      Self LMS       |     Binary     | Whether the student's institution has its own LMS |                Yes, No                |
|       Device        |    Nominal     |        Student's most used device in class        |         Computer, Tab, Mobile         |
|  Adaptivity Level   |    Ordinal     | Student's adaptibility level to online education  |          High, Moderate, Low          |

------------------------------------------------------------------------

## Data Summarization and Preprocessing:

#### Installing the packages

```{r}
install.packages("dplyr")
install.packages("farver")
install.packages("ggplot2")
install.packages("colorspace")
install.packages("scatterplot3d")
install.packages("gridExtra")
install.packages("superml")
install.packages('party')
install.packages("rpart")
install.packages("rpart.plot")
install.packages("rattle")
```

#### Reading libraries and the dataset

```{r}
library(rpart)
library(rpart.plot)
library(rattle)
library(rpart.plot)
library(RColorBrewer)
library(scatterplot3d)
library(ggplot2)
library(dplyr)
library(readr)
library(gridExtra)
library('superml')
library(caret)
library(party)
library(fpc)
library(FSelector)
library(cluster)
library(factoextra)
library('DPBBM')

dataset <- read_csv("Dataset/students_adaptability_level_online_education.csv")
```

#### Sample and summary of raw dataset

```{r}
View(dataset)

shape<-dim(dataset)
row<-shape[1]
col<-shape[2]
print(paste("Number of rows are:", row))
print(paste("Number of columns are:", col))

summary(dataset)
names(dataset)
str(dataset)
```

#### Missing values

```{r}
sum(is.na(dataset))
```

Since there are no missing values, and since there are no numerical data to be checked for outliers, we will move to the next step

All attribute types are char, so we can't calculate variance or do discretization.

------------------------------------------------------------------------

### Plotting Methods:

#### Bar plot of the gender, age, and education level attributes

```{r}
# Bar plot of the gender attribute
ggplot(dataset, mapping = aes(x = Gender)) +
  geom_bar(aes(fill = Gender), position = "dodge")

# Bar plot of the age attribute
ggplot(dataset, mapping = aes(x = Age)) +
  geom_bar(aes(fill = Age), position = "dodge")

# Bar plot of the education level attribute
ggplot(dataset, mapping = aes(x = `Education Level`)) +
  geom_bar(aes(fill = `Education Level`), position = "dodge")
```

Graphs decsriptions:

Gender plot: this graph shows us that the number of students who are boys are slightly more than the girl students.

Age plot: this graph shows us the number of students whose data been collected based on their age range, we noticed they are mostly between the ages of 21-25 and 11-15.

Education level plot: this graph shows us that the dataset is mostly collected from school and university students, and only a small number was collected from college students.

------------------------------------------------------------------------

#### Mosaic plot of the educational level attribute with the financial condition

```{r}
#Mosaic plot of the educational level attribute with the financial condition
counts <- table(dataset$'Education Level', dataset$'Financial Condition')
mosaicplot(counts, xlab='Education Level', ylab='Financial Condition',
           main='Education Level by Financial Condition', col='forestgreen')
```

Graph description: this graph shows us a visual comparison between students' financial condition against there education level, we noticed that in each education level category, students mostly come from a middle-class family regarding their financial condition.

------------------------------------------------------------------------

#### Pie chart for the self-LMS, IT student, and the adaptivity level attributes

```{r}
# Pie chart for the self-LMS attribute
tab <- dataset$'Self Lms'%>% table()
precentages <- tab %>% prop.table() %>% round(2) * 100 
txt <- paste0(names(tab), '\n', precentages, '%') 
pie(tab, labels=txt, main = "Distribution of self-LMS")

# Pie chart for the IT student attribute
tab <- dataset$'IT Student'%>% table()
precentages <- tab %>% prop.table() %>% round(2) * 100 
txt <- paste0(names(tab), '\n', precentages, '%') 
pie(tab, labels=txt, main = "Distribution of IT student")

# Pie chart for the adaptivity level attribute
tab <- dataset$'Adaptivity Level' %>% table()
percentages <- tab %>% prop.table() %>% round(3) * 100
txt <- paste0(names(tab), '\n', percentages, '%')
pie(tab, labels = txt, main = "Distribution of Adaptivity Levels")

```

Graphs descriptions:

Self-LMS chart: the graph shows us the percentage of institutions that has their own LMS, we notice that most of them, by a 83% percentage, do not have their own.

IT-Student chart: the graph shows us the percentage of students who are studying IT, we notice that most of them, by a 75% percentage, are not.

Adaptivity level chart: the graphs shows us the percentages of students adaptivity level in online education, which is our class label, we notice that most of them, by a 51.9% percentage, have a moderate adaptivity level, 39.8% have a low adaptivity level, and only 8.3% have a high adaptivity level.

------------------------------------------------------------------------

Since this dataset only contains categorical data, discreization and normalization cannot be performed.

------------------------------------------------------------------------

#### Encoding categorical variables

```{r}
# Encoding categorical attributes
categorical_cols <- dataset %>%
  select_if(is.character) %>%
  names()
categorical_cols
# Convert categorical columns to factors
dataset[categorical_cols] <- lapply(dataset[categorical_cols], as.factor)
```

------------------------------------------------------------------------

#### Chi Square

```{r}
chisq.test(datasetEncoded$'Institution Type', datasetEncoded$'Financial Condition')

```

since the p value is less than 0.05, therefore, the institution type depends on the financial condition.

------------------------------------------------------------------------

## Data Mining Tasks:

### Classification:

#### 1- 90/10 distribution:

Splitting the data into training and testing tests

```{r}
set.seed(1234)
split90 <- createDataPartition(dataset$`Adaptivity Level`, p = 0.9, list = FALSE, times = 1)
trainData <- dataset[split90,]
testData <- dataset[split90,]
```

Checking that both the training and testing sets have the same label proportions

```{r}
train90Prop <- trainData %>% 
  select(`Adaptivity Level`) %>% 
  group_by(`Adaptivity Level`) %>% 
  summarize(n = n()) %>% 
  mutate(pct = round(prop.table(n), 2))

test90Prop <- testData %>% 
  select(`Adaptivity Level`) %>% 
  group_by(`Adaptivity Level`) %>% 
  summarize(n = n()) %>% 
  mutate(pct = round(prop.table(n), 2))

train90Prop
test90Prop
```

They are proportionate, next is building decision tress for each attribute selection measure:

```{r}

infoGainTree <- rpart(formula = `Adaptivity Level` ~ ., data = trainData, method = "class", parms = list(split = "information"))
gainRatioTree <- rpart(formula = `Adaptivity Level` ~ ., data = trainData, method = "class", parms = list(split = "anova"))
GiniIndexTree <- rpart(formula = `Adaptivity Level` ~ ., data = trainData, method = "class", parms = list(split = "gini"))
```

1.  Information Gain

```{r}

IG1.ctree <- ctree(infoGainTree, data = trainData)
table(predict(IG1.ctree), trainData$`Adaptivity Level`)

print(IG1.ctree)
plot(IG1.ctree, type="simple")

testPred <- predict(IG1.ctree, newdata = testData)
result<-table(testPred, testData$`Adaptivity Level`)

results <- confusionMatrix(testPred, testData$`Adaptivity Level`)
print(results)
```

2.  Gain Ratio

```{r}
GR1.ctree <- ctree(gainRatioTree, data = trainData)
table(predict(GR1.ctree), trainData$`Adaptivity Level`)

print(GR1.ctree)
plot(GR1.ctree, type="simple")

testPred <- predict(GR1.ctree, newdata = testData)
result<-table(testPred, testData$`Adaptivity Level`)

results <- confusionMatrix(testPred, testData$`Adaptivity Level`)
print(results)
```

Calculating evaluation metrics

```{r}
confusion_matrix <- confusionMatrix(data = testPred, reference = testData$`Adaptivity Level`)
# Calculate evaluation metrics
accuracy <- confusion_matrix$overall["Accuracy"]
accuracy
# Calculate precision
precision <- confusion_matrix$table[2,2] / sum(confusion_matrix$table[,2])
precision
as.matrix(results, what = "overall")

```

3.  Gini Index

```{r}
GI1.ctree <- ctree(GiniIndexTree, data = trainData)
table(predict(GI1.ctree), trainData$`Adaptivity Level`)

print(GI1.ctree)
plot(GI1.ctree, type="simple")

testPred <- predict(GI1.ctree, newdata = testData)
result<-table(testPred, testData$`Adaptivity Level`)

results <- confusionMatrix(testPred, testData$`Adaptivity Level`)
print(results)
```

#### 2- 80/20 distribution:

Splitting the data into training and testing tests

```{r}
set.seed(1234)
split80 <- createDataPartition(dataset$`Adaptivity Level`, p = 0.8, list = FALSE, times = 1)
trainData <- dataset[split80,]
testData <- dataset[split80,]
```

Checking that both the training and testing sets have the same label proportions

```{r}
train80Prop <- trainData %>% 
  select(`Adaptivity Level`) %>% 
  group_by(`Adaptivity Level`) %>% 
  summarize(n = n()) %>% 
  mutate(pct = round(prop.table(n), 2))

test80Prop <- testData %>% 
  select(`Adaptivity Level`) %>% 
  group_by(`Adaptivity Level`) %>% 
  summarize(n = n()) %>% 
  mutate(pct = round(prop.table(n), 2))

train80Prop
test80Prop
```

They are proportionate, next is building decision tress for each attribute selection measure:

```{r}
infoGainTree <- rpart(formula = `Adaptivity Level` ~ ., data = trainData, method = "class", parms = list(split = "information"))
gainRatioTree <- rpart(formula = `Adaptivity Level` ~ ., data = trainData, method = "class", parms = list(split = "anova"))
GiniIndexTree <- rpart(formula = `Adaptivity Level` ~ ., data = trainData, method = "class", parms = list(split = "gini"))
```

1.  Information Gain

    ```{r}
    IG2.ctree <- ctree(infoGainTree, data = trainData)
    table(predict(IG2.ctree), trainData$`Adaptivity Level`)

    print(IG2.ctree)
    plot(IG2.ctree, type="simple")

    testPred <- predict(IG2.ctree, newdata = testData)
    result<-table(testPred, testData$`Adaptivity Level`)

    results <- confusionMatrix(testPred, testData$`Adaptivity Level`)
    print(results)
    ```

2.  Gain Ratio

    ```{r}
    GR2.ctree <- ctree(gainRatioTree, data = trainData)
    table(predict(GR2.ctree), trainData$`Adaptivity Level`)

    print(GR2.ctree)
    plot(GR2.ctree, type="simple")

    testPred <- predict(GR2.ctree, newdata = testData)
    result<-table(testPred, testData$`Adaptivity Level`)
    ```

Calculating evaluation metrics

```{r}
confusion_matrix <- confusionMatrix(data = testPred, reference = testData$`Adaptivity Level`)
# Calculate evaluation metrics
accuracy <- confusion_matrix$overall["Accuracy"]
accuracy
# Calculate precision
precision <- confusion_matrix$table[2,2] / sum(confusion_matrix$table[,2])
precision
as.matrix(results, what = "overall")
```

3.  Gini Index

```{r}
GI2.ctree <- ctree(GiniIndexTree, data = trainData)
table(predict(GI2.ctree), trainData$`Adaptivity Level`)

print(GI2.ctree)
plot(GI2.ctree, type="simple")

testPred <- predict(GI2.ctree, newdata = testData)
result<-table(testPred, testData$`Adaptivity Level`)

results <- confusionMatrix(testPred, testData$`Adaptivity Level`)
print(results)

```

#### 3- 70/30 distribution:

Splitting the data into training and testing tests

```{r}
set.seed(1234)
split70 <- createDataPartition(dataset$`Adaptivity Level`, p = 0.7, list = FALSE, times = 1)
trainData <- dataset[split70,]
testData <- dataset[split70,]
```

Checking that both the training and testing sets have the same label proportions

```{r}
train70Prop <- trainData %>% 
  select(`Adaptivity Level`) %>% 
  group_by(`Adaptivity Level`) %>% 
  summarize(n = n()) %>% 
  mutate(pct = round(prop.table(n), 2))

test70Prop <- testData %>% 
  select(`Adaptivity Level`) %>% 
  group_by(`Adaptivity Level`) %>% 
  summarize(n = n()) %>% 
  mutate(pct = round(prop.table(n), 2))

train70Prop
test70Prop
```

They are proportionate, next is building decision tress for each attribute selection measure:

```{r}
infoGainTree <- rpart(formula = `Adaptivity Level` ~ ., data = trainData, method = "class", parms = list(split = "information"))
gainRatioTree <- rpart(formula = `Adaptivity Level` ~ ., data = trainData, method = "class", parms = list(split = "anova"))
GiniIndexTree <- rpart(formula = `Adaptivity Level` ~ ., data = trainData, method = "class", parms = list(split = "gini"))
```

1.  Information Gain

    ```{r}
    IG3.ctree <- ctree(infoGainTree, data = trainData)
    table(predict(IG3.ctree), trainData$`Adaptivity Level`)

    print(IG3.ctree)
    plot(IG3.ctree, type="simple")

    testPred <- predict(IG3.ctree, newdata = testData)
    result<-table(testPred, testData$`Adaptivity Level`)

    results <- confusionMatrix(testPred, testData$`Adaptivity Level`)
    print(results)
    ```

2.  Gain Ratio

```{r}
GR3.ctree <- ctree(gainRatioTree, data = trainData)
table(predict(GR3.ctree), trainData$`Adaptivity Level`)

print(GR3.ctree)
plot(GR3.ctree, type="simple")

testPred <- predict(GR3.ctree, newdata = testData)
result<-table(testPred, testData$`Adaptivity Level`)
```

Calculating evaluation metrics

```{r}
confusion_matrix <- confusionMatrix(data = testPred, reference = testData$`Adaptivity Level`)
# Calculate evaluation metrics
accuracy <- confusion_matrix$overall["Accuracy"]
accuracy
# Calculate precision
precision <- confusion_matrix$table[2,2] / sum(confusion_matrix$table[,2])
precision
as.matrix(results, what = "overall")

```

3.  Gini Index

```{r}
GI3.ctree <- ctree(GiniIndexTree, data = trainData)
table(predict(GI3.ctree), trainData$`Adaptivity Level`)

print(GI3.ctree)
plot(GI3.ctree, type="simple")

testPred <- predict(GI3.ctree, newdata = testData)
result<-table(testPred, testData$`Adaptivity Level`)

results <- confusionMatrix(testPred, testData$`Adaptivity Level`)
print(results)
```

### Findings:

#### 1- 90/10 Distribution summary:

Accuracy: 77.05%

Precision: 77.31%

Sensitivity: 74.47%

Specificity: 86.61%

#### 2- 80/20 Distribution summary:

Accuracy: 75.31%

Precision: 60.41%

Sensitivity: 71.97%

Specificity: 84.69%

#### 3- 70/30 Distribution summary:

Accuracy: 75.71%

Precision: 73.81%

Sensitivity: 67.16%

Specificity: 84.96%

#### 4- Overall:

We find from the collected and presented data that the accuracy ranges between 0.7531 and 0.7705, which is good even if we go with the lowest value, and that a 90/10 distribution showed the best accuracy, precision, sensitivity, and specificity.

------------------------------------------------------------------------

### Clustring:

```{r}
# load the dataset 
df<-dataset


#drop the class label (Adaptivity Level))
df<-df[1:13]
str(df)

distinct_data_points <- nrow(unique(df))
print(distinct_data_points)
```

#### Performing K-Means Clustering with K=5, K=4, K=2, K=3 (The Best)

```{r}

#make this example reproducible
set.seed(1234)

df_numeric <- as.data.frame(lapply(df, as.numeric))

# Determine the maximum value of k you want to try
max_k <- 5

# Create an empty list to store the results
kmeans_results <- list()

# Loop through different k values
for (k in 1:max_k) {
  kmeans_results[[k]] <- kmeans(df_numeric, centers = k, nstart = 25)
}
```

1.  K = 5

    ```{r}
    k5_results <- kmeans_results[[5]]
    k5_results
    ```

    ```{r}
    # Visualize the clustering
    fviz_cluster(kmeans_results[[5]], data = df_numeric, geom = "point")

    # Evaluate and compare the clustering results
    silhouette_score <- silhouette(kmeans_results[[5]]$cluster, dist(df_numeric))
    silhouette_score


    # Calculate the total within-cluster sum of squares
    within_cluster_sum_squares <- kmeans_results[[5]]$tot.withins
    within_cluster_sum_squares



    Bcubed_score <- BCubed_metric(dataset$`Adaptivity Level`, kmeans_results[[5]]$cluster,0.5)
    Bcubed_score

    df1<-data.frame(Actual=dataset$`Adaptivity Level`,cluster=kmeans_results[[5]]$cluster)
    head(df1,15)
    cont_table <- table(df1$Actual, df1$cluster)
    cont_table
    differences <- sum(apply(cont_table, 1, max)) - sum(diag(cont_table))
    differences
    heatmap(cont_table, 
            col = heat.colors(max(cont_table)),
            main = "Cluster Assignments vs. Actual Class Labels",
            xlab = "Cluster Labels",
            ylab = "Actual Class Labels")
    ```

2.  K = 4

```{r}
k4_results <- kmeans_results[[4]]
k4_results
```

```{r}
# Visualize the clustering
fviz_cluster(kmeans_results[[4]], data = df_numeric, geom = "point")

# Evaluate and compare the clustering results
silhouette_score <- silhouette(kmeans_results[[4]]$cluster, dist(df_numeric))
silhouette_score


# Calculate the total within-cluster sum of squares
within_cluster_sum_squares <- kmeans_results[[4]]$tot.withins
within_cluster_sum_squares



Bcubed_score <- BCubed_metric(dataset$`Adaptivity Level`, kmeans_results[[4]]$cluster,0.5)
Bcubed_score

df1<-data.frame(Actual=dataset$`Adaptivity Level`,cluster=kmeans_results[[4]]$cluster)
head(df1,15)
cont_table <- table(df1$Actual, df1$cluster)
cont_table
differences <- sum(apply(cont_table, 1, max)) - sum(diag(cont_table))
differences
heatmap(cont_table, 
        col = heat.colors(max(cont_table)),
        main = "Cluster Assignments vs. Actual Class Labels",
        xlab = "Cluster Labels",
        ylab = "Actual Class Labels")
```

3.  K = 2

    ```{r}
    k2_results <- kmeans_results[[2]]
    k2_results
    ```

```{r}
# Visualize the clustering
fviz_cluster(kmeans_results[[2]], data = df_numeric, geom = "point")

# Evaluate and compare the clustering results
silhouette_score <- silhouette(kmeans_results[[2]]$cluster, dist(df_numeric))
silhouette_score


# Calculate the total within-cluster sum of squares
within_cluster_sum_squares <- kmeans_results[[2]]$tot.withins
within_cluster_sum_squares



Bcubed_score <- BCubed_metric(dataset$`Adaptivity Level`, kmeans_results[[2]]$cluster,0.5)
Bcubed_score

df1<-data.frame(Actual=dataset$`Adaptivity Level`,cluster=kmeans_results[[2]]$cluster)
head(df1,15)
cont_table <- table(df1$Actual, df1$cluster)
cont_table
differences <- sum(apply(cont_table, 1, max)) - sum(diag(cont_table))
differences
heatmap(cont_table, 
        col = heat.colors(max(cont_table)),
        main = "Cluster Assignments vs. Actual Class Labels",
        xlab = "Cluster Labels",
        ylab = "Actual Class Labels")
```

3.  K = 3

    ```{r}
    k3_results <- kmeans_results[[3]]
    k3_results
    ```

    ```{r}
    # Visualize the clustering
    fviz_cluster(kmeans_results[[3]], data = df_numeric, geom = "point")

    # Evaluate and compare the clustering results
    silhouette_score <- silhouette(kmeans_results[[3]]$cluster, dist(df_numeric))
    silhouette_score


    # Calculate the total within-cluster sum of squares
    within_cluster_sum_squares <- kmeans_results[[3]]$tot.withins
    within_cluster_sum_squares



    Bcubed_score <- BCubed_metric(dataset$`Adaptivity Level`, kmeans_results[[3]]$cluster,0.5)
    Bcubed_score

    df1<-data.frame(Actual=dataset$`Adaptivity Level`,cluster=kmeans_results[[3]]$cluster)
    head(df1,15)
    cont_table <- table(df1$Actual, df1$cluster)
    cont_table
    differences <- sum(apply(cont_table, 1, max)) - sum(diag(cont_table))
    differences
    heatmap(cont_table, 
            col = heat.colors(max(cont_table)),
            main = "Cluster Assignments vs. Actual Class Labels",
            xlab = "Cluster Labels",
            ylab = "Actual Class Labels")
    ```
